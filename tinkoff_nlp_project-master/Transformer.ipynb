{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"1jBXsBb452_M","colab_type":"text"},"cell_type":"markdown","source":["<b>Transformer</b>\n","\n","adapted from: https://github.com/zhangxiangnick/Transformer-py"]},{"metadata":{"id":"5BolmIKv6mfM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":189},"outputId":"10dbf4b7-e27a-46ce-cec2-4ae20d5b2e9d","executionInfo":{"status":"ok","timestamp":1556001265534,"user_tz":-180,"elapsed":21299,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"kMTI_x9786KN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":656},"outputId":"398ad602-cdf9-4736-944b-22f38a1e3657","executionInfo":{"status":"ok","timestamp":1556001449237,"user_tz":-180,"elapsed":129659,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["! pip install pycuda"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pycuda\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/33/cced4891eddd1a3ac561ff99081019fddc7838a07cace272c941e3c2f915/pycuda-2018.1.1.tar.gz (1.6MB)\n","\u001b[K    100% |████████████████████████████████| 1.6MB 19.0MB/s \n","\u001b[?25hCollecting pytools>=2011.2 (from pycuda)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a3/f54f7190315ad41b7334d8733350e7fcefded8f25e0b45e2329b80279921/pytools-2019.1.tar.gz (57kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 27.6MB/s \n","\u001b[?25hRequirement already satisfied: pytest>=2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (3.6.4)\n","Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.0)\n","Collecting appdirs>=1.4.0 (from pycuda)\n","  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n","Collecting mako (from pycuda)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/bb/f4e5c056e883915c37bb5fb6fab7f00a923c395674f83bfb45c9ecf836b6/Mako-1.0.9.tar.gz (459kB)\n","\u001b[K    100% |████████████████████████████████| 460kB 30.5MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.11.0)\n","Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.16.2)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (1.3.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (19.1.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (1.8.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (7.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (40.9.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n","Building wheels for collected packages: pycuda, pytools, mako\n","  Building wheel for pycuda (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a5/17/ac/99922221c732eeece43529d3e0f9d441f7301c75990b2cdbff\n","  Building wheel for pytools (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/1b/f4/26/46b6cf949b3cccefcc41e6b526f7c16351a4a5c124fc6f6eaa\n","  Building wheel for mako (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/46/23/48/366f0d8b14d436e58ad0aef531b14af8d8beabeb2986704bd5\n","Successfully built pycuda pytools mako\n","Installing collected packages: appdirs, pytools, mako, pycuda\n","Successfully installed appdirs-1.4.3 mako-1.0.9 pycuda-2018.1.1 pytools-2019.1\n"],"name":"stdout"}]},{"metadata":{"id":"3ForMTeu74Fw","colab_type":"text"},"cell_type":"markdown","source":["### Нужные классы и функции"]},{"metadata":{"id":"x12JRXg68z6D","colab_type":"code","colab":{}},"cell_type":"code","source":["import collections\n","import datetime\n","import inspect\n","import logging\n","import os\n","import signal\n","import types\n","from pprint import pprint\n","\n","import dill\n","import torch\n","import torch.nn.init as init\n","from pycuda import autoinit, driver\n","from torch import nn\n","\n","\n","#######################################################################################################################\n","\n","def gpu_stat():\n","    if torch.cuda.is_available():\n","\n","        def pretty_bytes(byte_, precision=1):\n","            abbrevs = (\n","                (1 << 50, 'PB'), (1 << 40, 'TB'), (1 << 30, 'GB'), (1 << 20, 'MB'), (1 << 10, 'kB'), (1, 'bytes'))\n","            if byte_ == 1:\n","                return '1 byte'\n","            factor, suffix = 1, ''\n","            for factor, suffix in abbrevs:\n","                if byte_ >= factor:\n","                    break\n","            return '%.*f%s' % (precision, byte_ / factor, suffix)\n","\n","        device = autoinit.device\n","        print('GPU Name: %s' % device.name())\n","        print('GPU Memory: %s' % pretty_bytes(device.total_memory()))\n","        print('CUDA Version: %s' % str(driver.get_version()))\n","        print('GPU Free/Total Memory: %d%%' % ((driver.mem_get_info()[0] / driver.mem_get_info()[1]) * 100))\n","\n","\n","#######################################################################################################################\n","\n","\n","class HYPERPARAMETERS(collections.OrderedDict):\n","    \"\"\"\n","    Class to make it easier to access hyper parameters by either dictionary or attribute syntax.\n","    \"\"\"\n","\n","    def __init__(self, dictionary):\n","        super(HYPERPARAMETERS, self).__init__(dictionary)\n","\n","    def __getattr__(self, name):\n","        return self[name]\n","\n","    def __setattr__(self, name, value):\n","        self[name] = value\n","\n","    def __getstate__(self):\n","        return self\n","\n","    def __setstate__(self, d):\n","        self = d\n","\n","    def pprint(self, path):\n","        with open(path, \"w+\") as h_file:\n","            pprint(self, stream=h_file)\n","\n","    @staticmethod\n","    def create_timestamp(ts=None):\n","        ts = datetime.datetime.now().timestamp() if ts is None else ts\n","        dts = datetime.datetime.fromtimestamp(ts)\n","        return '{:04d}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}-{:06d}'.format(dts.year, dts.month, dts.day, dts.hour,\n","                                                                         dts.minute, dts.second, dts.second,\n","                                                                         dts.microsecond)\n","\n","    @staticmethod\n","    def convert_timestamp(time_str=None):\n","        dts = datetime.datetime(*[int(parts) for parts in time_str.split('-')])\n","        return dts.timestamp()\n","\n","    @staticmethod\n","    def load(path):\n","        with open(path, 'rb') as in_strm:\n","            h = dill.load(in_strm)\n","        return h\n","\n","    @staticmethod\n","    def dump(h, path):\n","        with open(path, 'wb') as out_strm:\n","            dill.dump(h, out_strm)\n","\n","    def __repr__(self):\n","        fmt_str = '{' + '\\n'\n","        for k, v in self.items():\n","            if '__class__' in k:\n","                continue\n","            if isinstance(v, types.LambdaType):  # function or lambda\n","                if v.__name__ in '<lambda>':\n","                    try:\n","                        fmt_str += inspect.getsource(v)\n","                    except:\n","                        fmt_str += \"    \" + \"'{}'\".format(k).ljust(32) + \": '\" + str(v) + \"' ,\\n\"\n","                else:\n","                    fmt_str += \"    \" + \"'{}'\".format(k).ljust(32) + ': ' + v.__name__ + ' ,\\n'\n","            elif isinstance(v, type):  # class\n","                fmt_str += \"    \" + \"'{}'\".format(k).ljust(32) + ': ' + v.__name__ + ' ,\\n'\n","            else:  # everything else\n","                if isinstance(v, str):\n","                    fmt_str += \"    \" + \"'{}'\".format(k).ljust(32) + \": '\" + str(v) + \"' ,\\n\"\n","                else:\n","                    fmt_str += \"    \" + \"'{}'\".format(k).ljust(32) + ': ' + str(v) + ' ,\\n'\n","        fmt_str += '}\\n'\n","        return fmt_str\n","\n","\n","#######################################################################################################################\n","\n","\n","class Metric(object):\n","    \"\"\"\n","    Class to track runtime statistics easier. Inspired by History Variables that not only store the current value,\n","    but also the values previously assigned. (see https://rosettacode.org/wiki/History_variables)\n","    \"\"\"\n","\n","    def __init__(self, metrics):\n","        self.metrics = [m[0] for m in metrics]\n","        self.init_vals = {m[0]: m[1] for m in metrics}\n","        self.values = {}\n","        for name in self.metrics:\n","            self.values[name] = []\n","\n","    def __setattr__(self, name, value):\n","        self.__dict__[name] = value\n","        if name in self.metrics:\n","            self.values[name].append(value)\n","\n","    def __getattr__(self, attr):\n","        if attr in self.metrics and not len(self.values[attr]):\n","            val = self.init_vals[attr]\n","        else:\n","            val = self.__dict__[attr]\n","        return val\n","\n","    def values(self, metric):\n","        return self.values[metric]\n","\n","    def state_dict(self):\n","        state = {}\n","        for m in self.metrics:\n","            state[m] = self.values[m]\n","        return state\n","\n","    def load_state_dict(self, state_dict):\n","        for m in state_dict:\n","            self.values[m] = state_dict[m]\n","\n","\n","#######################################################################################################################\n","# https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5\n","\n","\n","def torch_weight_init(m):\n","    \"\"\"\n","    Usage:\n","        model = Model()\n","        model.apply(weight_init)\n","    \"\"\"\n","    if isinstance(m, nn.Conv1d):\n","        init.normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.Conv2d):\n","        init.xavier_normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.Conv3d):\n","        init.xavier_normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.ConvTranspose1d):\n","        init.normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.ConvTranspose2d):\n","        init.xavier_normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.ConvTranspose3d):\n","        init.xavier_normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.BatchNorm1d):\n","        init.normal(m.weight.data, mean=1, std=0.02)\n","        init.constant(m.bias.data, 0)\n","    elif isinstance(m, nn.BatchNorm2d):\n","        init.normal(m.weight.data, mean=1, std=0.02)\n","        init.constant(m.bias.data, 0)\n","    elif isinstance(m, nn.BatchNorm3d):\n","        init.normal(m.weight.data, mean=1, std=0.02)\n","        init.constant(m.bias.data, 0)\n","    elif isinstance(m, nn.Linear):\n","        init.xavier_normal(m.weight.data)\n","        init.normal(m.bias.data)\n","    elif isinstance(m, nn.LSTM):\n","        for param in m.parameters():\n","            if len(param.shape) >= 2:\n","                init.orthogonal(param.data)\n","            else:\n","                init.normal(param.data)\n","    elif isinstance(m, nn.LSTMCell):\n","        for param in m.parameters():\n","            if len(param.shape) >= 2:\n","                init.orthogonal(param.data)\n","            else:\n","                init.normal(param.data)\n","    elif isinstance(m, nn.GRU):\n","        for param in m.parameters():\n","            if len(param.shape) >= 2:\n","                init.orthogonal(param.data)\n","            else:\n","                init.normal(param.data)\n","    elif isinstance(m, nn.GRUCell):\n","        for param in m.parameters():\n","            if len(param.shape) >= 2:\n","                init.orthogonal(param.data)\n","            else:\n","                init.normal(param.data)\n","    elif isinstance(m, nn.Embedding):\n","        m.weight.data.uniform_(-0.1, 0.1)\n","\n","#######################################################################################################################\n","\n","def create_logger(H):\n","    if not os.path.exists(H.EXPERIMENT):\n","        os.makedirs(H.EXPERIMENT)\n","\n","    logFormatter = logging.Formatter('%(asctime)s | %(levelname)s : %(message)s')\n","\n","    fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(H.EXPERIMENT, H.MODEL_NAME))\n","    fileHandler.setFormatter(logFormatter)\n","\n","    consoleHandler = logging.StreamHandler()\n","    consoleHandler.setFormatter(logFormatter)\n","\n","    logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n","                        level=logging.INFO, handlers=[consoleHandler, fileHandler])\n","\n","\n","#######################################################################################################################\n","# https://github.com/SeanNaren/deepspeech.pytorch/blob/master/model.py\n","\n","\n","class SequenceWise(nn.Module):\n","    def __init__(self, module):\n","        \"\"\"\n","        Collapses input of dim T*N*H to (T*N)*H, and applies to a module.\n","        Allows handling of variable sequence lengths and minibatch sizes.\n","        :param module: Module to apply input to.\n","        \"\"\"\n","        super(SequenceWise, self).__init__()\n","        self.module = module\n","\n","    def forward(self, x):\n","        t, n = x.size(0), x.size(1)\n","        x = x.contiguous().view(t * n, -1)\n","        x = self.module(x)\n","        x = x.view(t, n, -1)\n","        return x\n","\n","    def __repr__(self):\n","        tmpstr = self.__class__.__name__ + ' (\\n'\n","        tmpstr += self.module.__repr__()\n","        tmpstr += ')'\n","        return tmpstr\n","\n","\n","#######################################################################################################################\n","# https://stackoverflow.com/questions/842557/how-to-prevent-a-block-of-code-from-being-interrupted-by-keyboardinterrupt-in-py\n","\n","\n","class DelayedKeyboardInterrupt(object):\n","    def __init__(self):\n","        self.signal_received = None\n","\n","    def __enter__(self):\n","        self.signal_received = None\n","        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n","\n","    def handler(self, sig, frame):\n","        self.signal_received = (sig, frame)\n","        print('SIGINT received. Delaying KeyboardInterrupt.')\n","\n","    def __exit__(self, type_, value, traceback):\n","        signal.signal(signal.SIGINT, self.old_handler)\n","        if self.signal_received:\n","            self.old_handler(*self.signal_received)\n","\n","#######################################################################################################################\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qa09hBdv78iD","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import shutil\n","\n","import torch\n","\n","\n","#######################################################################################################################\n","# https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/util/checkpoint.py\n","\n","\n","class Checkpoint(object):\n","    \"\"\"\n","    Class that manages the saving and loading of a model during training. It allows training to be suspended\n","    and resumed at a later time.\n","    \"\"\"\n","\n","    def __init__(self, module, optimizer=None, stopping=None, metrics=None,\n","                 root_dir='./', experiment_dir=\"model\", restore_from=-1, interval=10, verbose=0):\n","\n","        self.CHECKPOINT_DIR_NAME = 'chkpt'\n","        self.CHECKPOINT_FILE_NAME = 'state.tar'\n","\n","        self.module = module\n","        self.optimizer = optimizer\n","        self.stopping = stopping\n","        self.metrics = metrics\n","        self.interval = interval\n","\n","        self.root_dir = root_dir\n","        self.experiment_dir = experiment_dir\n","        self.restore_from = restore_from\n","        self.verbose = verbose\n","\n","        self.timestamp = None\n","\n","    def create(self, epoch):\n","        \"\"\"\n","        Creates a checkpoint of the current model and related training parameters into a subdirectory of the checkpoint\n","        directory. The name of the subdirectory is the current local time in Y_M_D_H_M_S format.\n","        \"\"\"\n","\n","        self.timestamp = HYPERPARAMETERS.create_timestamp()\n","        path = os.path.join(self.root_dir, self.CHECKPOINT_DIR_NAME, self.experiment_dir, self.timestamp)\n","\n","        if os.path.exists(path):\n","            shutil.rmtree(path)\n","\n","        os.makedirs(path)\n","\n","        state = {\n","            'timestamp': self.timestamp,\n","            'epoch': epoch,\n","            'module': self.module.state_dict(),\n","            'optimizer': self.optimizer.state_dict() if self.optimizer else None,\n","            'stopping': self.stopping.state_dict() if self.stopping else None,\n","            'metrics': self.metrics.state_dict() if self.metrics else None\n","        }\n","\n","        torch.save(state, os.path.join(path, self.CHECKPOINT_FILE_NAME))\n","\n","        if self.verbose:\n","            print(\"Created checkpoint in '{}' \".format(path))\n","\n","    def restore(self):\n","        \"\"\"\n","        Restores a current model and related training parameters from a checkpoint object that was previously\n","        saved to disk.\n","        \"\"\"\n","\n","        file_name = self.last()\n","\n","        assert file_name is not None\n","\n","        state = torch.load(file_name)\n","\n","        self.timestamp = state['timestamp']\n","        self.module.load_state_dict(state['module'])\n","        if self.optimizer:\n","            self.optimizer.load_state_dict(state['optimizer'])\n","        if self.stopping:\n","            self.stopping.load_state_dict(state['stopping'])\n","        if self.metrics:\n","            self.metrics.load_state_dict(state['metrics'])\n","\n","        if self.verbose:\n","            print(\"Restored checkpoint from '{}' \".format(file_name))\n","\n","        return state['epoch']\n","\n","    def step(self, epoch):\n","        \"\"\"\"\"\"\n","        if not epoch % self.interval:\n","            self.create(epoch)\n","            if self.verbose:\n","                print(\"Epoch: %d checkpoint created!\" % epoch)\n","\n","    def last(self):\n","        \"\"\"\n","        Returns the path to the last saved checkpoint file for a given set of parameters.\n","        Precondition: at least one checkpoint has been made (i.e., latest checkpoint subdirectory exists).\n","         \"\"\"\n","        checkpoints_path = os.path.join(self.root_dir, self.CHECKPOINT_DIR_NAME, self.experiment_dir)\n","\n","        try:\n","            path = sorted(os.listdir(checkpoints_path), reverse=False)[self.restore_from]\n","\n","            last_path = os.path.join(checkpoints_path, os.path.join(path, self.CHECKPOINT_FILE_NAME))\n","        except:\n","            last_path = \"undefined\"\n","\n","        return last_path\n","\n","    def __repr__(self):\n","        fmt_str = self.__class__.__name__ + '\\n'\n","        fmt_str += '    Timestamp: {}\\n'.format(self.timestamp)\n","        fmt_str += '    Last Checkpoint: {}\\n'.format(self.last())\n","        return fmt_str\n","\n","#######################################################################################################################\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ife-IGjt-jr_","colab_type":"code","colab":{}},"cell_type":"code","source":["import copy\n","\n","\n","#######################################################################################################################\n","\n","\n","class Stopping(object):\n","    \"\"\"\n","    Class implement some of regularization techniques to avoid over-training as described in\n","    http://page.mi.fu-berlin.de/prechelt/Biblio/stop_tricks1997.pdf\n","    \"\"\"\n","\n","    def __init__(self, model, patience=50):\n","        self.model = model\n","        self.patience = patience\n","\n","        self.best_score = -1\n","        self.best_score_epoch = 0\n","        self.best_score_state = None\n","\n","    def step(self, epoch, train_score, valid_score):\n","        if valid_score > self.best_score:\n","            self.best_score = valid_score\n","            self.best_score_epoch = epoch\n","            self.best_score_state = copy.deepcopy(self.model.state_dict())\n","            return False\n","        elif self.best_score_epoch + self.patience < epoch:\n","            return True\n","\n","    def state_dict(self):\n","        return {\n","            'patience': self.patience,\n","            'best_score': self.best_score,\n","            'best_score_epoch': self.best_score_epoch,\n","            'best_score_state': self.best_score_state,\n","        }\n","\n","    def load_state_dict(self, state_dict):\n","        self.patience = state_dict['patience']\n","        self.best_score = state_dict['best_score']\n","        self.best_score_epoch = state_dict['best_score_epoch']\n","        self.best_score_state = state_dict['best_score_state']\n","\n","    def __repr__(self):\n","        fmt_str = self.__class__.__name__ + '\\n'\n","        fmt_str += '    Patience: {}\\n'.format(self.patience)\n","        fmt_str += '    Best Score: {:.4f}\\n'.format(self.best_score)\n","        fmt_str += '    Epoch of Best Score: {}\\n'.format(self.best_score_epoch)\n","        return fmt_str\n","\n","#######################################################################################################################\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0-TXaRTA-sOy","colab_type":"code","colab":{}},"cell_type":"code","source":["from collections import Counter\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import sklearn\n","import torch\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","from IPython.display import display\n","from graphviz import Digraph\n","from sklearn import metrics\n","\n","\n","#######################################################################################################################\n","\n","\n","def visualize_data(img, tks, vocab, figsize=None, ax=None):\n","    if img.size(0) is 3:\n","        pil_img = transforms.ToPILImage()(img)\n","        pil_img = pil_img.convert('L')\n","        img = transforms.ToTensor()(pil_img)\n","\n","    img = img.squeeze().cpu().numpy()\n","    if isinstance(tks, str):\n","        txt = tks\n","    else:\n","        txt = ''.join([vocab.idx2token[tkn.item()] for tkn in tks])\n","\n","    if figsize is not None:\n","        plt.figure(figsize=figsize)\n","\n","    if not ax:\n","        plt.title(txt)\n","        plt.imshow(img, cmap='gray')\n","    else:\n","        ax.set_title(txt)\n","        ax.imshow(img, cmap='gray')\n","\n","\n","###################################################################################################################\n","\n","\n","def plot_learning_curves(m, loss_ylim=(0, 1.0), score_ylim=(0.0, 1.0), figsize=(14, 6)):\n","    train_loss = m.values['train_loss'] if 'train_loss' in m.values else None\n","    train_score = m.values['train_score'] if 'train_score' in m.values else None\n","    train_lr = m.values['train_lr'] if 'train_lr' in m.values else None\n","    valid_loss = m.values['valid_loss'] if 'valid_loss' in m.values else None\n","    valid_ppl = m.values['valid_ppl'] if 'valid_ppl' in m.values else None\n","    valid_score = m.values['valid_score'] if 'valid_score' in m.values else None\n","\n","    train_epochs = np.linspace(1, len(train_loss), len(train_loss))\n","\n","    fig, ax = plt.subplots(1, 2, figsize=figsize)\n","\n","    if train_loss is not None:\n","        loss_train_min = np.min(train_loss)\n","        ax[0].plot(train_epochs, train_loss, color=\"r\",\n","                   label=\"Trainings loss (min %.4f)\" % loss_train_min)  # alpha=0.3)\n","\n","    if valid_loss is not None:\n","        loss_valid_min = np.min(valid_loss)\n","        ax[0].plot(train_epochs, valid_loss, color=\"b\",\n","                   label=\"Validation loss (min %.4f)\" % loss_valid_min)  # alpha=0.3)\n","        ax[0].legend(loc=\"best\")\n","\n","    if train_lr is not None:\n","        ax0 = ax[0].twinx()\n","        ax0.plot(train_epochs, train_lr, color=\"g\", label=\"Learning Rate\")  # alpha=0.3)\n","        ax0.set_ylabel('learning rate')\n","\n","    ax[0].set_title(\"Loss\")\n","    ax[0].set_xlim(0, np.max(train_epochs))\n","    ax[0].set_ylim(*loss_ylim)\n","    ax[0].set_xlabel('epochs')\n","    ax[0].set_ylabel('loss')\n","\n","    if train_score is not None:\n","        score_train_max = np.max(train_score)\n","        ax[1].plot(train_epochs, train_score, color=\"r\",\n","                   label=\"Trainings score (max %.4f)\" % score_train_max)\n","\n","    if valid_score is not None:\n","        score_valid_max = np.max(valid_score)\n","        ax[1].plot(train_epochs, valid_score, color=\"b\",\n","                   label=\"Validation score (max %.4f)\" % score_valid_max)\n","\n","    if train_lr is not None:\n","        ax1 = ax[1].twinx()\n","        ax1.plot(train_epochs, train_lr, color=\"g\", label=\"Learning Rate\")  # alpha=0.3)\n","        ax1.set_ylabel('learning rate')\n","\n","    ax[1].set_title(\"Score\")\n","    ax[1].set_xlim(0, np.max(train_epochs))\n","    ax[1].set_ylim(*score_ylim)\n","    ax[1].set_xlabel('epochs')\n","    ax[1].set_ylabel('score')\n","    ax[1].legend(loc=\"best\")\n","\n","    plt.grid(False)\n","    plt.tight_layout()\n","\n","\n","#####################################################################################################################\n","\n","\n","def plot_cross_validation_scores(scores, figsize=(12, 4)):\n","    train_score = scores['train_score']\n","    valid_scores = scores['test_score']\n","    score_difference = train_score - valid_scores\n","\n","    plt.figure(figsize=figsize)\n","    plt.subplot(211)\n","\n","    train_score_line, = plt.plot(train_score, color='r')\n","    valid_scores_line, = plt.plot(valid_scores, color='b')\n","    plt.ylabel(\"Score\", fontsize=\"14\")\n","    plt.legend([train_score_line, valid_scores_line], [\"Train CV\", \"Validate CV\"], bbox_to_anchor=(0, .4, .5, 0))\n","    plt.title(\"Train and Validation Cross Validation\", x=.5, y=1.1, fontsize=\"15\")\n","\n","    # Plot bar chart of the difference.\n","    plt.subplot(212)\n","    difference_plot = plt.bar(range(len(score_difference)), score_difference)\n","    plt.xlabel(\"Cross-fold #\")\n","    plt.legend([difference_plot], [\"Test CV - Validation CV Score\"], bbox_to_anchor=(0, 1, .8, 0))\n","    plt.ylabel(\"Score difference\", fontsize=\"14\")\n","\n","    plt.show()\n","\n","\n","#####################################################################################################################\n","\n","\n","def plot_roc_curve(y_true, y_pred, y_proba):\n","    plt.figure()\n","\n","    fpr, tpr, _ = metrics.roc_curve(y_true, y_proba[:, 1])\n","    plt.plot(fpr, tpr, color='red', label=\"predict_proba\")\n","\n","    fpr, tpr, _ = metrics.roc_curve(y_true, y_pred)\n","    plt.plot(fpr, tpr, color='darkorange', label=\"predict\")\n","\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic')\n","    plt.legend(loc=\"lower right\")\n","\n","\n","#####################################################################################################################\n","# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","import matplotlib\n","from matplotlib import cm\n","import itertools\n","\n","\n","def cm2inch(*tupl):\n","    '''\n","    Specify figure size in centimeter in matplotlib\n","    Source: http://stackoverflow.com/a/22787457/395857\n","    By gns-ank\n","    '''\n","    inch = 2.54\n","    if type(tupl[0]) == tuple:\n","        return tuple(i / inch for i in tupl[0])\n","    else:\n","        return tuple(i / inch for i in tupl)\n","\n","\n","def show_values(pc, fmt=\"%.2f\", **kw):\n","    '''\n","    Heatmap with text in each cell with matplotlib's pyplot\n","    Source: http://stackoverflow.com/a/25074150/395857\n","    By HYRY\n","    '''\n","    pc.update_scalarmappable()\n","    ax = pc.axes\n","    for p, color, value in zip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n","        x, y = p.vertices[:-2, :].mean(0)\n","        if np.all(color[:3] > 0.5):\n","            color = (0.0, 0.0, 0.0)\n","        else:\n","            color = (1.0, 1.0, 1.0)\n","        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)\n","\n","\n","def get_cmap():\n","    '''\n","    http://stackoverflow.com/questions/37517587/how-can-i-change-the-intensity-of-a-colormap-in-matplotlib\n","    '''\n","    cmap = cm.get_cmap('RdBu', 256)  # set how many colors you want in color map\n","    # modify colormap\n","    alpha = 1.0\n","    colors = []\n","    for ind in range(cmap.N):\n","        c = []\n","        if ind < 128 or ind > 210: continue\n","        for x in cmap(ind)[:3]: c.append(min(1, x * alpha))\n","        colors.append(tuple(c))\n","    my_cmap = matplotlib.colors.ListedColormap(colors, name='my_name')\n","    return my_cmap\n","\n","\n","def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, ax, correct_orientation=False,\n","            cmap='RdBu', fmt=\"%.2f\", graph_filepath='', normalize=False, remove_diagonal=False):\n","    '''\n","    Inspired by:\n","    - http://stackoverflow.com/a/16124677/395857\n","    - http://stackoverflow.com/a/25074150/395857\n","    '''\n","    if normalize:\n","        AUC = sklearn.preprocessing.normalize(AUC, norm='l1', axis=1)\n","\n","    if remove_diagonal:\n","        matrix = np.copy(AUC)\n","        np.fill_diagonal(matrix, 0)\n","        if len(xticklabels) > 2:\n","            matrix[:, -1] = 0\n","            matrix[-1, :] = 0\n","        values = matrix.flatten()\n","    else:\n","        values = AUC.flatten()\n","    vmin = values.min()\n","    vmax = values.max()\n","\n","    # c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap='RdBu', vmin=0.0, vmax=1.0)\n","    c = ax.pcolor(AUC, edgecolors='k', linestyle='dashed', linewidths=0.2, cmap=get_cmap(), vmin=vmin, vmax=vmax)\n","\n","    # put the major ticks at the middle of each cell\n","    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n","    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n","\n","    # set tick labels\n","    ax.set_xticklabels(xticklabels, minor=False)\n","    ax.set_yticklabels(yticklabels, minor=False)\n","\n","    # set title and x/y labels\n","    plt.title(title, y=1.08)\n","\n","    plt.tight_layout()\n","\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","\n","    # Remove last blank column\n","    plt.xlim((0, AUC.shape[1]))\n","\n","    # Turn off all the ticks\n","    ax = plt.gca()\n","    for t in ax.xaxis.get_major_ticks():\n","        t.tick1On = False\n","        t.tick2On = False\n","    for t in ax.yaxis.get_major_ticks():\n","        t.tick1On = False\n","        t.tick2On = False\n","\n","    # Add color bar\n","    plt.colorbar(c)\n","\n","    # Add text in each cell\n","    show_values(c, fmt=fmt)\n","\n","    # Proper orientation (origin at the top left instead of bottom left)\n","    if correct_orientation:\n","        ax.invert_yaxis()\n","        ax.xaxis.tick_top()\n","\n","    if graph_filepath != '':\n","        plt.savefig(graph_filepath, dpi=300, format='png', bbox_inches='tight')\n","        plt.close()\n","\n","\n","def plot_classification_report(classification_report, title='Classification report ', cmap='RdBu',\n","                               figsize=(12, 9), ax=None):\n","    '''\n","    Plot scikit-learn classification report.\n","    Extension based on http://stackoverflow.com/a/31689645/395857\n","    '''\n","\n","    from matplotlib.cbook import MatplotlibDeprecationWarning\n","    import warnings\n","    warnings.simplefilter('ignore', MatplotlibDeprecationWarning)\n","\n","    classes = []\n","    plotMat = []\n","    support = []\n","    class_names = []\n","\n","    lines = classification_report.split('\\n')\n","    for line in lines[2: (len(lines) - 1)]:\n","        t = line.strip().replace('avg / total', 'micro-avg').split()\n","        if len(t) < 2: continue\n","        classes.append(t[0])\n","        v = [float(x) * 100 for x in t[1: len(t) - 1]]\n","        support.append(int(t[-1]))\n","        class_names.append(t[0])\n","        plotMat.append(v)\n","\n","    xlabel = 'Metrics'\n","    ylabel = 'Classes'\n","    xticklabels = ['Precision', 'Recall', 'F1-score']\n","    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup in enumerate(support)]\n","    #    figure_width = 16\n","    #    figure_height = len(class_names) + 8\n","    correct_orientation = True\n","\n","    # Plot it out\n","    if ax is None:\n","        fig, ax = plt.subplots(figsize=figsize)\n","    else:\n","        fig = plt.gcf()\n","        fig.sca(ax)\n","\n","    heatmap(np.array(plotMat), title, xlabel, ylabel, xticklabels, yticklabels, ax, correct_orientation, cmap=cmap)\n","\n","    # resize\n","    # fig.set_size_inches(cm2inch(figsize[0], figsize[1]))\n","\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Greens, ax=None):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","\n","    if not ax is None:\n","        plt.gcf().sca(ax)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title, y=1.08)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    ax.xaxis.set_label_position('top')\n","\n","\n","def plot_classifier_summary(y_true, y_pred, target_names, figsize=(12, 5)):\n","    fig, ax = plt.subplots(1, 2, figsize=figsize)\n","\n","    plot_classification_report(classification_report(y_true, y_pred, target_names=target_names), ax=ax[0])\n","    plot_confusion_matrix(confusion_matrix(y_true, y_pred), target_names, False, ax=ax[1])\n","\n","\n","####################################################################################################################\n","\n","from sklearn.manifold import TSNE\n","\n","\n","def plot_scatter_plots(X, y_pred, y_proba, y_true, target_names, figsize=(12, 4)):\n","    tsne = TSNE(n_components=2, init='pca', random_state=0)\n","    tsne_data = tsne.fit_transform(X)\n","\n","    idx = y_pred != y_true\n","\n","    # set up figure\n","    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n","\n","    # Plot\n","    ax1.scatter(tsne_data[np.where(y_true == 1), 0], tsne_data[np.where(y_true == 1), 1],\n","                c='r', label=target_names[1])\n","    ax1.scatter(tsne_data[np.where(y_true == 0), 0], tsne_data[np.where(y_true == 0), 1],\n","                c='b', label=target_names[0])\n","\n","    ax1.scatter(tsne_data[idx, 0], tsne_data[idx, 1], alpha=.8, lw=2, label=\"Error\",\n","                facecolors='none', edgecolors='black', marker='o', s=80)\n","\n","    ax2.scatter(y_proba[np.where(y_true == 1), 0], y_proba[np.where(y_true == 1), 1], c='r', label=target_names[1])\n","    ax2.scatter(y_proba[np.where(y_true == 0), 0], y_proba[np.where(y_true == 0), 1], c='b', label=target_names[0])\n","\n","    ax2.scatter(y_proba[idx, 0], y_proba[idx, 1], alpha=.8, lw=2, label=\"Error\",\n","                facecolors='none', edgecolors='black', marker='o', s=80)\n","\n","    ax1.axes.get_xaxis().set_ticks([])\n","    ax1.axes.get_yaxis().set_ticks([])\n","    ax2.axes.get_xaxis().set_ticks([])\n","    ax2.axes.get_yaxis().set_ticks([])\n","\n","    fig.suptitle('Scatter Plots', fontsize=20, fontweight='bold')\n","    plt.legend(loc=2, borderaxespad=.1, scatterpoints=1, bbox_to_anchor=(1.05, 1))\n","\n","    fig.text(.25, .05, 'TSNE Test Data', fontsize=15)\n","    fig.text(.65, .05, 'CLF Proba Data', fontsize=15)\n","\n","\n","###################################################################################################################\n","\n","def classifier_summary_report(X, y_true, y_pred, target_names):\n","    valid_score = metrics.f1_score(y_true, y_pred)\n","    acc_score = metrics.accuracy_score(y_true, y_pred)\n","    roc_score = metrics.roc_auc_score(y_true, y_pred)\n","    loss_score = metrics.log_loss(y_true, y_pred)\n","\n","    print(\"Note: weighted average f1-score \\n\",\n","          metrics.classification_report(y_true, y_pred, target_names=target_names)\n","          )\n","\n","    display(\n","        'Data points=%d' % X.shape[0],\n","        'Features=%d' % X.shape[1],\n","        'Class dist.=%f' % np.mean(y_true),\n","        'F1 valid=%f' % valid_score,\n","        'ACC=%f' % acc_score,\n","        'ROC_AUC=%f' % roc_score,\n","        'LOG_LOSS=%f' % loss_score,\n","        'Misclassified=%d' % np.sum(y_true != y_pred),\n","        'Data points=' + str([i for (i, v) in enumerate(y_true != y_pred) if v][:20])\n","    )\n","\n","\n","###################################################################################################################\n","\n","def class_info(classes):\n","    counts = Counter(classes)\n","    total = sum(counts.values())\n","    print(\"class percentages:\")\n","    for cls in counts.keys():\n","        print(\"%6s: % 7d  =  % 5.1f%%\" % (cls, counts[cls], counts[cls] / total * 100))\n","\n","\n","def dataset_statistics(X_train, y_train, X_valid, y_valid, X_test, y_test, target_names):\n","    print(\"\")\n","    print(\"Dataset statistics:\")\n","    print(\"===================\")\n","    print(\"%s %d\" % (\"number of features:\".ljust(30), X_train.shape[1]))\n","    print(\"%s %d\" % (\"number of classes:\".ljust(30), np.unique(y_train).shape[0]))\n","    print(\"%s %s\" % (\"data type:\".ljust(30), X_train.dtype))\n","    print(\"%s %d (size=%dMB)\"\n","          % (\"number of train samples:\".ljust(30), X_train.shape[0], int(X_train.nbytes / 1e6)))\n","    print(\"%s %d (size=%dMB)\"\n","          % (\"number of validation samples:\".ljust(30), X_valid.shape[0], int(X_valid.nbytes / 1e6)))\n","    print(\"%s %d (size=%dMB)\"\n","          % (\"number of test samples:\".ljust(30), X_test.shape[0], int(X_test.nbytes / 1e6)))\n","    print(\"%s %s\" % (\"classes\".ljust(30), str(target_names)))\n","    class_info(y_train)\n","\n","\n","###################################################################################################################\n","\n","def plot_loss_curve(train_loss, train_score=None, valid_loss=None, valid_score=None, train_lr=None):\n","    train_epochs = np.linspace(1, len(train_loss), len(train_loss))\n","\n","    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n","\n","    if not train_loss is None:\n","        loss_train_min = np.min(train_loss)\n","        ax[0].plot(train_epochs, train_loss, color=\"r\",\n","                   label=\"Trainings loss (min %.4f)\" % loss_train_min)  # alpha=0.3)\n","\n","    if not valid_loss is None:\n","        loss_valid_min = np.min(valid_loss)\n","        ax[0].plot(train_epochs, valid_loss, color=\"b\",\n","                   label=\"Validation loss (min %.4f)\" % loss_valid_min)  # alpha=0.3)\n","\n","    if not train_lr is None:\n","        ax0 = ax[0].twinx()\n","        ax0.plot(train_epochs, train_lr, color=\"g\", label=\"Learning Rate\")  # alpha=0.3)\n","        ax0.set_ylabel('lr')\n","\n","    ax[0].set_title(\"Loss\")\n","    ax[0].set_xlim(0, np.max(train_epochs))\n","    #     ax[0].set_ylim(0, 1)\n","    ax[0].set_xlabel('epochs')\n","    ax[0].set_ylabel('loss')\n","    ax[0].grid(True)\n","    ax[0].legend(loc=\"best\")\n","\n","    if not train_score is None:\n","        score_train_max = np.max(train_score)\n","        ax[1].plot(train_epochs, train_score, color=\"r\",\n","                   label=\"Trainings score (max %.4f)\" % score_train_max)\n","\n","    if not valid_score is None:\n","        score_valid_max = np.max(valid_score)\n","        ax[1].plot(train_epochs, valid_score, color=\"b\",\n","                   label=\"Validation score (max %.4f)\" % score_valid_max)\n","\n","    ax[1].set_title(\"Score\")\n","    ax[1].set_xlim(0, np.max(train_epochs))\n","    ax[1].set_ylim(0.0, 1.02)\n","    ax[1].set_xlabel('epochs')\n","    ax[1].set_ylabel('score')\n","    ax[1].grid(True)\n","    ax[1].legend(loc=\"best\")\n","\n","    plt.legend(loc=\"best\")\n","\n","\n","#####################################################################################################################\n","\n","# https://stackoverflow.com/questions/42480111/model-summary-in-pytorch\n","# https://github.com/fchollet/keras/blob/master/keras/utils/layer_utils.py\n","\n","def model_summary(model, line_length=None, positions=None):\n","    \"\"\"Prints a summary of a model.\n","    # Arguments\n","        model: model instance.\n","        line_length: Total length of printed lines\n","            (e.g. set this to adapt the display to different\n","            terminal window sizes).\n","        positions: Relative or absolute positions of log elements in each line.\n","            If not provided, defaults to `[.33, .55, .67, 1.]`.\n","        print_fn: Print function to use.\n","            It will be called on each line of the summary.\n","            You can set it to a custom function\n","            in order to capture the string summary.\n","    \"\"\"\n","    out_str = \"\"\n","    line_length = line_length or 80\n","    positions = positions or [.45, .85, 1.]\n","    if positions[-1] <= 1:\n","        positions = [int(line_length * p) for p in positions]\n","    # header names for the different log elements\n","    to_display = ['Layer (type)', 'Shape', 'Param #']\n","\n","    def print_row(fields, positions):\n","        line = ''\n","        for i in range(len(fields)):\n","            if i > 0:\n","                line = line[:-1] + ' '\n","            line += str(fields[i])\n","            line = line[:positions[i]]\n","            line += ' ' * (positions[i] - len(line))\n","        return line\n","\n","    out_str += \"Summary for model: \" + model.__class__.__name__ + \"\\n\"\n","    out_str += '_' * line_length + \"\\n\"\n","    out_str += print_row(to_display, positions) + \"\\n\"\n","    out_str += '=' * line_length + \"\\n\"\n","\n","    def print_module_summary(name, module):\n","        count_params = sum([np.prod(p.size()) for p in module.parameters()])\n","        output_shape = tuple([tuple(p.size()) for p in module.parameters()])\n","        cls_name = module.__class__.__name__\n","        fields = [name + ' (' + cls_name + ')', output_shape, count_params]\n","        return print_row(fields, positions)\n","\n","    module_count = len(set(model.modules()))\n","    for i, item in enumerate(model.named_modules()):\n","        name, module = item\n","        cls_name = str(module.__class__)\n","        if not 'torch' in cls_name or 'container' in cls_name:\n","            continue\n","\n","        out_str += print_module_summary(name, module) + \"\\n\"\n","        if i == module_count - 1:\n","            out_str += '=' * line_length + \"\\n\"\n","        else:\n","            out_str += '_' * line_length + \"\\n\"\n","\n","    trainable_count = 0\n","    non_trainable_count = 0\n","    for name, param in model.named_parameters():\n","        if 'bias' in name or 'weight' in name:\n","            trainable_count += np.prod(param.size())\n","        else:\n","            non_trainable_count += np.prod(param.size())\n","\n","    out_str += 'Total params:         {:,}'.format(trainable_count + non_trainable_count) + \"\\n\"\n","    out_str += 'Trainable params:     {:,}'.format(trainable_count) + \"\\n\"\n","    out_str += '_' * line_length + \"\\n\"\n","    return out_str\n","\n","\n","#####################################################################################################################\n","\n","def layer_weight(data):\n","    mean = np.mean(data)\n","    std = np.std(data)\n","\n","    hist, bins = np.histogram(data, bins=50)\n","    width = np.diff(bins)\n","    center = (bins[:-1] + bins[1:]) / 2\n","\n","    return {'mean': mean,\n","            'std': std,\n","            'hist': hist,\n","            'center': center,\n","            'width': width\n","            }\n","\n","\n","def plot_layer_stats(net):\n","    def to_np(x):\n","        return x.data.cpu().numpy()\n","\n","    for name, module in net.named_modules():\n","        weight_attr = ['weight', 'weight_ih_l0', 'weight_hh_l0']\n","        weight_list = [w for w in weight_attr if hasattr(module, w)]\n","\n","        bias_attr = ['bias', 'bias_ih_l0', 'bias_hh_l0']\n","        bias_list = [b for b in bias_attr if hasattr(module, b)]\n","\n","        if not (weight_list and bias_list):\n","            continue\n","\n","        for idx in range(len(weight_attr)):\n","            plt.figure(idx, figsize=(10, 4))\n","\n","            if hasattr(module, weight_attr[idx]):\n","                if type(getattr(module, weight_attr[idx])) is torch.nn.parameter.Parameter:\n","                    w = layer_weight(to_np(getattr(module, weight_attr[idx])))\n","\n","                    ax = plt.subplot2grid((1, 2), (0, 0))\n","                    ax.set_title(\"Module: %s-\" % name + weight_attr[idx] +\n","                                 \"\\n Mean # %.4f\" % w['mean'] + \" STD # %.2e\" % w['std'])\n","                    ax.bar(w['center'], w['hist'], align='center', width=w['width'])\n","\n","            if hasattr(module, bias_attr[idx]):\n","                if type(getattr(module, bias_attr[idx])) is torch.nn.parameter.Parameter:\n","                    b = layer_weight(to_np(getattr(module, bias_attr[idx])))\n","\n","                    ax = plt.subplot2grid((1, 2), (0, 1))\n","                    ax.set_title(\"Module: %s-\" % name + bias_attr[idx] +\n","                                 \"\\n Mean # %.4f\" % b['mean'] + \" STD # %.2e\" % b['std'])\n","                    ax.bar(b['center'], b['hist'], align='center', width=b['width'])\n","\n","            plt.show()\n","\n","\n","#####################################################################################################################\n","\n","def plot_model_graph(var, params):\n","    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n","\n","    Blue nodes are the Variables that require grad, orange are Tensors\n","    saved for backward in torch.autograd.Function\n","\n","    Args:\n","        var: output Variable\n","        params: dict of (name, Variable) to add names to node that\n","            require grad (TODO: make optional)\n","    \"\"\"\n","    param_map = {id(v): k for k, v in params.items()}\n","\n","    node_attr = dict(style='filled',\n","                     shape='box',\n","                     align='left',\n","                     fontsize='12',\n","                     ranksep='0.1',\n","                     height='0.2')\n","    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"8,8\"))\n","    seen = set()\n","\n","    def size_to_str(size):\n","        # noinspection PyRedundantParentheses\n","        return '(' + (', ').join(['%d' % v for v in size]) + ')'\n","\n","    def add_nodes(var):\n","        if var not in seen:\n","            if torch.is_tensor(var):\n","                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n","            elif hasattr(var, 'variable'):\n","                u = var.variable\n","                node_name = '%s\\n %s' % (param_map.get(id(u)), size_to_str(u.size()))\n","                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n","            else:\n","                dot.node(str(id(var)), str(type(var).__name__))\n","            seen.add(var)\n","            if hasattr(var, 'next_functions'):\n","                for u in var.next_functions:\n","                    if u[0] is not None:\n","                        dot.edge(str(id(u[0])), str(id(var)))\n","                        add_nodes(u[0])\n","            if hasattr(var, 'saved_tensors'):\n","                for t in var.saved_tensors:\n","                    dot.edge(str(id(t)), str(id(var)))\n","                    add_nodes(t)\n","\n","    add_nodes(var.grad_fn)\n","    return dot\n","\n","###################################################################################################################\n","\n","# from imblearn.base import *\n","# from imblearn.utils import check_target_type, hash_X_y\n","# import logging\n","#\n","#\n","# class OutlierSampler(SamplerMixin):\n","#     def __init__(self, threshold=1.5, memory=None, verbose=0):\n","#         self.threshold = threshold\n","#         self.verbose = verbose\n","#         self.logger = logging.getLogger(__name__)\n","#\n","#         self.X_hash_, self.y_hash_ = None, None\n","#\n","#     def sample(self, X, y):\n","#         # Check the consistency of X and y\n","#         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc'])\n","#\n","#         check_is_fitted(self, 'X_hash_')\n","#         self._check_X_y(X, y)\n","#\n","#         X_out, y_out = self._sample(X, y)\n","#\n","#         return X_out, y_out\n","#\n","#     def _sample(self, X, y):\n","#         outliers = []\n","#         for col in X.T:  # loop over feature columns\n","#             Q1 = np.percentile(col, 25)  # Calculate Q1 (25th percentile of the data) for the given feature\n","#             Q3 = np.percentile(col, 75)  # Calculate Q3 (75th percentile of the data) for the given feature\n","#\n","#             step = self.threshold * (Q3 - Q1)  # Use the interquartile range to calculate an outlier step\n","#\n","#             feature_outliers = np.where(~((col >= Q1 - step) & (col <= Q3 + step)))[0]\n","#             outliers.extend(feature_outliers)\n","#\n","#         # Find the data points that where considered outliers for more than one feature\n","#         multi_feature_outliers = list((Counter(outliers) - Counter(set(outliers))).keys())\n","#\n","#         X_out = np.delete(X, multi_feature_outliers, axis=0)\n","#         y_out = np.delete(y, multi_feature_outliers, axis=0)\n","#\n","#         if self.verbose:\n","#             print('Sampled - reduced points form / to: ', X.shape, X_out.shape)\n","#         return X_out, y_out\n","#\n","#     def fit(self, X, y):\n","#         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc'])\n","#         y = check_target_type(y)\n","#         self.X_hash_, self.y_hash_ = hash_X_y(X, y)\n","#\n","#         self._fit(X, y)\n","#\n","#         return self\n","#\n","#     def _fit(self, X, y):\n","#         if self.verbose:\n","#             print('OutlierSampler Fitted X/y: ', X.shape, y.shape)\n","#         return self\n","#\n","#     def fit_sample(self, X, y):\n","#         return self.fit(X, y).sample(X, y)\n","\n","###################################################################################################################\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JWqh_RAF-4EP","colab_type":"code","colab":{}},"cell_type":"code","source":["import inspect\n","import os\n","import shutil\n","\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","\n","#######################################################################################################################\n","\n","\n","class TensorboardLogger(object):\n","    \"\"\" Visualize the training results of running a pytorch model to Tensorboard \"\"\"\n","\n","    def __init__(self, root_dir=\"./\", experiment_dir=\"model\", verbose=0):\n","        self.root_dir = root_dir\n","        self.experiment_dir = experiment_dir\n","        self.verbose = verbose\n","\n","        self.LOG_DIR_NAME = 'logs'\n","\n","        self.iterable = None\n","\n","        self.last_logged_values = []\n","        self.epoch = -1\n","\n","        date_time = HYPERPARAMETERS.create_timestamp()\n","        path = os.path.join(self.root_dir, self.LOG_DIR_NAME, self.experiment_dir, date_time)\n","\n","        if os.path.exists(path):\n","            shutil.rmtree(path)\n","\n","        os.makedirs(path)\n","\n","        self.writer = tf.summary.FileWriter(path)\n","\n","    def set_itr(self, iterable):\n","        self.iterable = iterable\n","        return self\n","\n","    def __iter__(self):\n","\n","        assert self.iterable is not None\n","\n","        for obj in self.iterable:\n","            self.epoch = obj\n","            yield obj\n","\n","    def log_values(self, train_loss, train_score, train_lr,\n","                   valid_loss, valid_score, best_score_epoch, best_score):\n","\n","        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n","        self.last_logged_values = [(i, values[i]) for i in args[1:]]\n","\n","        summary = tf.Summary(value=[\n","            tf.Summary.Value(tag='train_loss', simple_value=train_loss),\n","            tf.Summary.Value(tag='train_score', simple_value=train_score),\n","            tf.Summary.Value(tag='train_lr', simple_value=train_lr),\n","            tf.Summary.Value(tag='valid_loss', simple_value=valid_loss),\n","            tf.Summary.Value(tag='valid_score', simple_value=valid_score),\n","            tf.Summary.Value(tag='best_score_epoch', simple_value=best_score_epoch),\n","            tf.Summary.Value(tag='best_score', simple_value=best_score)\n","        ])\n","        self.writer.add_summary(summary, self.epoch)\n","\n","    def __repr__(self):\n","        fmt_str = self.__class__.__name__ + '\\n'\n","        fmt_str += '    Last Epoch/LR:    {} / {}\\n'.format(self.epoch, self.last_logged_values[2][1])\n","        fmt_str += '    Train Loss/Score: {} / {}\\n'.format(self.last_logged_values[0][1],\n","                                                            self.last_logged_values[1][1])\n","        fmt_str += '    Valid Loss/Score: {} / {}\\n'.format(self.last_logged_values[3][1],\n","                                                            self.last_logged_values[4][1])\n","        fmt_str += '    Best Epoch/Score: {} / {}\\n'.format(self.last_logged_values[5][1],\n","                                                            self.last_logged_values[6][1])\n","        return fmt_str\n","\n","\n","#######################################################################################################################\n","\n","\n","class PytorchLogger(object):\n","    \"\"\" Visualize the training results of running a pytorch model using Tqdm \"\"\"\n","\n","    def __init__(self, tqdm_cls=tqdm):\n","        self.iterable = None\n","        self.last_logged_values = []\n","        self.epoch = -1\n","        self.tqdm_cls = tqdm_cls\n","\n","    def set_itr(self, iterable):\n","        self.iterable = iterable\n","        self.iterable = self.tqdm_cls(iterable)\n","        self.iterable.set_description('Epoch')\n","        return self\n","\n","    def __iter__(self):\n","        assert self.iterable is not None\n","\n","        for obj in self.iterable:\n","            self.epoch = obj\n","            yield obj\n","\n","    def log_values(self, train_loss, train_score, train_lr,\n","                   valid_loss, valid_score, best_score_epoch, best_score):\n","        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n","        self.last_logged_values = [(i, values[i]) for i in args[1:]]\n","\n","        self.iterable.set_postfix(last=\"%i\" % self.epoch + \"/%.4f\" % train_loss + \"/%.4f\" % train_score,\n","                                  lr=train_lr,\n","                                  best=\"%i\" % best_score_epoch + \"/%.4f\" % best_score)\n","\n","    def __repr__(self):\n","        fmt_str = self.__class__.__name__ + '\\n'\n","        fmt_str += '    Last Epoch/LR:    {} / {}\\n'.format(self.epoch, self.last_logged_values[2][1])\n","        fmt_str += '    Train Loss/Score: {} / {}\\n'.format(self.last_logged_values[0][1],\n","                                                            self.last_logged_values[1][1])\n","        fmt_str += '    Valid Loss/Score: {} / {}\\n'.format(self.last_logged_values[3][1],\n","                                                            self.last_logged_values[4][1])\n","        fmt_str += '    Best Epoch/Score: {} / {}\\n'.format(self.last_logged_values[5][1],\n","                                                            self.last_logged_values[6][1])\n","        return fmt_str\n","\n","#######################################################################################################################\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t7KBanSV_DKM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":395},"outputId":"86d7d4bd-ede3-4254-eea3-49dc7227ec5e","executionInfo":{"status":"ok","timestamp":1556001485088,"user_tz":-180,"elapsed":8277,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["! pip install watermark"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting watermark\n","  Downloading https://files.pythonhosted.org/packages/4b/dc/fb451c174b4f603231875c9ca7116d1b81cdd635172f0fbab248b1d94cd5/watermark-1.8.1-py3-none-any.whl\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from watermark) (5.5.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (4.3.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (40.9.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (2.1.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (4.7.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (4.4.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark) (1.0.16)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->watermark) (0.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->watermark) (1.11.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->watermark) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (0.1.7)\n","Installing collected packages: watermark\n","Successfully installed watermark-1.8.1\n"],"name":"stdout"}]},{"metadata":{"id":"Zb7Ac-vB79cH","colab_type":"text"},"cell_type":"markdown","source":["### Конец нужных классов и функций"]},{"metadata":{"id":"wuoXKVp452_R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"eb680b90-8e99-4bd8-9ea5-e6f8d3e99464","executionInfo":{"status":"ok","timestamp":1556001485090,"user_tz":-180,"elapsed":6104,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","import random\n","\n","from tqdm import tqdm_notebook\n","import numpy as np\n","import math, copy, time\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import torchtext\n","from torchtext.data import Field\n","\n","logger = logging.getLogger(__name__)\n","\n","%load_ext watermark\n","%watermark -a \"tb\" -d -v -m -p sys,numpy,pandas,sklearn,torch,IPython\n","gpu_stat()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tb 2019-04-23 \n","\n","CPython 3.6.7\n","IPython 5.5.0\n","\n","sys 3.6.7 (default, Oct 22 2018, 11:32:17) \n","[GCC 8.2.0]\n","numpy 1.16.2\n","pandas 0.24.2\n","sklearn 0.20.3\n","torch 1.0.1.post2\n","IPython 5.5.0\n","\n","compiler   : GCC 8.2.0\n","system     : Linux\n","release    : 4.14.79+\n","machine    : x86_64\n","processor  : x86_64\n","CPU cores  : 2\n","interpreter: 64bit\n","GPU Name: Tesla T4\n","GPU Memory: 14.7GB\n","CUDA Version: (10, 0, 0)\n","GPU Free/Total Memory: 99%\n"],"name":"stdout"}]},{"metadata":{"id":"pLeWD78u52_h","colab_type":"code","colab":{}},"cell_type":"code","source":["# torch.cuda.is_available = lambda : False\n","# torch.backends.cudnn.enabled=False\n","torch.backends.cudnn.deterministic = True\n","# torch.backends.cudnn.benchmark = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X7vm2Gda52_n","colab_type":"code","colab":{}},"cell_type":"code","source":["H = HYPERPARAMETERS({\n","    'EXPERIMENT': 'Eng2Ger',\n","    'DESCRIPTION': 'Transformer model',\n","    'TIMESTAMP': HYPERPARAMETERS.create_timestamp(),\n","\n","    'MODEL_NAME': 'Eng2Ger_TRANSFORMER',\n","\n","    'PRELOAD_MODEL_PATH': None,\n","\n","    'ROOT_DIR': 'data',\n","\n","    'TARGET_ENCODING': 'sts',  # ' ctc\n","\n","    'BATCH_SIZE': 64,\n","    'NUM_WORKERS': 8,\n","\n","    'EMBEDDING_SIZE': 256,\n","    'EMBEDDING_DROPOUT': 0.2,\n","    'RNN_HIDDEN_SIZE': 256,\n","    'RNN_NUM_LAYERS': 2,\n","    'RNN_DROPOUT': 0.2,\n","    'BIDIRECTIONAL': True,\n","\n","    'LR': 0.0003,\n","    'LR_LAMBDA': lambda epoch: max(math.pow(0.78, math.floor((1 + epoch) / 200.0)), 0.01),\n","    'WEIGHT_DECAY': 0,\n","    'MOMENTUM': 0.9,\n","    'NESTEROV': True,\n","\n","    'LABEL_SMOOTHING' : 0.2,\n","\n","    'MAX_GRAD_NORM': 1,\n","\n","    'MAX_EPOCHS': 30,\n","\n","    'STOPPING_PATIENCE': 80,\n","\n","    'CHECKPOINT_INTERVAL': 10,\n","    'CHECKPOINT_RESTORE': False,\n","\n","    'USE_CUDA': torch.cuda.is_available(),\n","\n","    'SEED': 123456,\n","    \n","    'SEQ_MAX_LEN' :         50,\n","    'SRC_VOCAB_MAX_SIZE' :  50000,\n","    'TGT_VOCAB_MAX_SIZE' :  50000,\n","\n","})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RrqAPIcq52_s","colab_type":"code","colab":{}},"cell_type":"code","source":["random.seed(H.SEED)\n","np.random.seed(H.SEED)\n","torch.manual_seed(H.SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(H.SEED)\n","    torch.cuda.manual_seed_all(H.SEED)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pfSJYFzG52_0","colab_type":"code","colab":{}},"cell_type":"code","source":["SYM_SOS = '<sos>'\n","SYM_EOS = '<eos>'\n","SYM_PAD = '<pad>'\n","IDX_SOS = -1\n","IDX_EOS = -1\n","IDX_PAD = -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aQ-IpZOJ5nyy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":242},"outputId":"1cb4153d-6112-4032-8012-d3a7020a503b","executionInfo":{"status":"ok","timestamp":1556001491315,"user_tz":-180,"elapsed":5196,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["!python -m spacy download en"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n","\n","\u001b[93m    Linking successful\u001b[0m\n","    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n","\n","    You can now load the model via spacy.load('en')\n","\n"],"name":"stdout"}]},{"metadata":{"id":"8fDBTm6b6pW2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"11a0d530-da90-4b83-dc27-5bc3c481a635","executionInfo":{"status":"ok","timestamp":1556001508251,"user_tz":-180,"elapsed":8128,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["!python -m spacy download de"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Collecting de_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz#egg=de_core_news_sm==2.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz (38.2MB)\n","\u001b[K    100% |████████████████████████████████| 38.2MB 105.1MB/s \n","\u001b[?25hInstalling collected packages: de-core-news-sm\n","  Running setup.py install for de-core-news-sm ... \u001b[?25ldone\n","\u001b[?25hSuccessfully installed de-core-news-sm-2.0.0\n","\n","\u001b[93m    Linking successful\u001b[0m\n","    /usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","    /usr/local/lib/python3.6/dist-packages/spacy/data/de\n","\n","    You can now load the model via spacy.load('de')\n","\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"ao_rQuLl6vH9","colab":{}},"cell_type":"code","source":["class Voc:\n","    def __init__(self, name):\n","        self.name = name\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.num_words\n","            self.word2count[word] = 1\n","            self.index2word[self.num_words] = word\n","            self.num_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    def trim(self, min_count):\n","        if self.trimmed:\n","            return\n","        self.trimmed = True\n","\n","        keep_words = []\n","\n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words {} / {} = {:.4f}'.format(\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3\n","\n","        for word in keep_words:\n","            self.addWord(word)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cj49vHeHAq9q","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DocoTdVRAsu0","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('gdrive/My Drive/Colab Notebooks/pairs.pickle', 'rb') as handle:\n","    pairs = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"fuR85Pq6D6Z_","colab":{}},"cell_type":"code","source":["with open('gdrive/My Drive/Colab Notebooks/voc.pickle', 'rb') as handle:\n","    voc = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K6AwbwGoAtny","colab_type":"code","colab":{}},"cell_type":"code","source":["def column(matrix, i):\n","    return [row[i] for row in matrix]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mugCOru3ByP8","colab_type":"code","colab":{}},"cell_type":"code","source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pcuj2DJx52_8","colab_type":"code","colab":{}},"cell_type":"code","source":["import spacy\n","\n","spacy_en = spacy.load('en')\n","spacy_de = spacy.load('de')\n","\n","def tokenize_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer( text )]\n","    return text.split()\n","\n","def tokenize_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(text)]\n","    return text.split()\n","\n","preproc = lambda seq: [SYM_SOS] + seq + [SYM_EOS]\n","\n","src = Field(sequential=True, tokenize=tokenize_en, lower=True, batch_first=True, \n","            include_lengths=True)\n","tgt = Field(sequential=True, tokenize=tokenize_de, lower=True, batch_first=True, \n","            include_lengths=True, preprocessing=preproc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kkRrAgZq7Q4i","colab_type":"code","colab":{}},"cell_type":"code","source":["def len_filter(example):\n","    return len(example.src) <= H.SEQ_MAX_LEN and len(example.tgt) <= H.SEQ_MAX_LEN\n","\n","path = \"gdrive/My Drive/Colab Notebooks/enggerdata.tsv\"\n","SRC_FIELD_NAME = 'src'\n","TGT_FIELD_NAME = 'tgt'\n","\n","train_data, valid_data, test_data = torchtext.data.TabularDataset(\n","    path=path, format='tsv',\n","    fields=[(SRC_FIELD_NAME, src), (TGT_FIELD_NAME, tgt)],\n","    filter_pred=len_filter\n","    ).split(split_ratio=[0.8, 0.1, 0.1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w3NOBYW953AE","colab_type":"code","colab":{}},"cell_type":"code","source":["class Vocabulary(object):\n","    def __init__(self, vocab):\n","        self.vocab = vocab\n","        \n","    def __call__(self, val):\n","        if isinstance(val, str):\n","            res = self.vocab.stoi[val] if val in self.vocab.stoi else None\n","        elif isinstance(val, int):\n","            res = self.vocab.itos[val] if val <= self.__len__() else None\n","        else:\n","            raise RuntimeError\n","        return res   \n","    \n","    def __len__(self):\n","        return len(self.vocab.itos)\n","    \n","    def __repr__(self):\n","        return 'Vocab(size=' + str(len(self.vocab.itos)) + ')'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S5jTMWGl53AI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"1fe420d9-7888-45fc-f70f-9213259417a5","executionInfo":{"status":"ok","timestamp":1556001856344,"user_tz":-180,"elapsed":2463,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["src.build_vocab(train_data, max_size=H.SRC_VOCAB_MAX_SIZE, min_freq=2)\n","tgt.build_vocab(train_data, max_size=H.TGT_VOCAB_MAX_SIZE, min_freq=2)\n","\n","input_vocab = Vocabulary(src.vocab)\n","output_vocab = Vocabulary(tgt.vocab)\n","\n","print(input_vocab, output_vocab)\n","\n","IDX_PAD = output_vocab(SYM_PAD)\n","IDX_SOS = output_vocab(SYM_SOS)\n","IDX_EOS = output_vocab(SYM_EOS)\n","\n","IDX_PAD, IDX_SOS, IDX_EOS"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Vocab(size=9510) Vocab(size=15657)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1, 3, 2)"]},"metadata":{"tags":[]},"execution_count":36}]},{"metadata":{"id":"MnBeIYb053AQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"85b3bf0f-7859-4f02-d416-8d3983072f1a","executionInfo":{"status":"ok","timestamp":1556001875552,"user_tz":-180,"elapsed":975,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits(\n","                                (train_data, valid_data, test_data), \n","                                batch_size=H.BATCH_SIZE, repeat=False, \n","                                sort=False, sort_within_batch=True, \n","                                sort_key=lambda x: len(x.src))\n","\n","\n","batch = next(train_iter.__iter__())\n","input_variables = getattr(batch, 'src')\n","target_variables = getattr(batch, 'tgt')\n","\n","len(train_iter), len(valid_iter), len(test_iter)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2115, 265, 265)"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"B0tNmU6s53AX","colab_type":"code","colab":{}},"cell_type":"code","source":["for idx_batch, batch in enumerate(train_iter):\n","    inputs_cpu, input_sizes_cpu = getattr(batch, SRC_FIELD_NAME)\n","    labels_cpu, label_sizes_cpu = getattr(batch, TGT_FIELD_NAME)\n","    break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mV0MxXaa53Ab","colab_type":"code","colab":{}},"cell_type":"code","source":["import math\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, dim, dropout=0.0, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dim = dim\n","        self.dropout = dropout\n","\n","        pe = torch.zeros(max_len, dim)\n","        position = torch.arange(0.0, max_len).unsqueeze(1).float()\n","        div_term = torch.exp((torch.arange(0.0, dim, 2) * -(math.log(10000.0) / dim)))\n","        pe[:, 0::2] = torch.sin(position.float() * div_term)\n","        pe[:, 1::2] = torch.cos(position.float() * div_term)\n","        pe = pe.unsqueeze(0)\n","\n","        self.register_buffer('pe', pe)\n","        self.dropout = nn.Dropout(p=self.dropout)\n","\n","    def forward(self, x):\n","        x = x * math.sqrt(self.dim)\n","        x = x + self.pe[:, :x.size(1)]\n","        x = self.dropout(x)\n","        return x\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, num_heads, d_model, droput):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.droput = droput\n","\n","        self.d_head = d_model // self.num_heads\n","\n","        self.fc_query = nn.Linear(self.d_model, self.num_heads * self.d_head, bias=False)\n","        self.fc_key = nn.Linear(self.d_model, self.num_heads * self.d_head, bias=False)\n","        self.fc_value = nn.Linear(self.d_model, self.num_heads * self.d_head, bias=False)\n","\n","        self.fc_concat = nn.Linear(self.num_heads * self.d_head, self.d_model, bias=False)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","        self.attn_dropout = nn.Dropout(self.droput)\n","        self.dropout = nn.Dropout(self.droput)\n","\n","        self.norm = nn.LayerNorm(self.d_model)\n","\n","    def _prepare_proj(self, x):\n","        \"\"\"Reshape the projectons to apply softmax on each head\n","        \"\"\"\n","        b, l, d = x.size()\n","        return x.view(b, l, self.num_heads, self.d_head).transpose(1, 2).contiguous().view(b * self.num_heads, l,\n","                                                                                           self.d_head)\n","\n","    def forward(self, query, key, value, mask):\n","        b, len_query = query.size(0), query.size(1)\n","        len_key = key.size(1)\n","\n","        # project inputs to multi-heads\n","        proj_query = self.fc_query(query)  # batch_size x len_query x h*d_head\n","        proj_key = self.fc_key(key)  # batch_size x len_key x h*d_head\n","        proj_value = self.fc_value(value)  # batch_size x len_key x h*d_head\n","\n","        # prepare the shape for applying softmax\n","        proj_query = self._prepare_proj(proj_query)  # batch_size*h x len_query x d_head\n","        proj_key = self._prepare_proj(proj_key)  # batch_size*h x len_key x d_head\n","        proj_value = self._prepare_proj(proj_value)  # batch_size*h x len_key x d_head\n","\n","        # get dotproduct softmax attns for each head\n","        attns = torch.bmm(proj_query, proj_key.transpose(1, 2))  # batch_size*h x len_query x len_key\n","        attns = attns / math.sqrt(self.d_head)\n","        attns = attns.view(b, self.num_heads, len_query, len_key)\n","        attns = attns.masked_fill_(mask.unsqueeze(1), -float('inf'))\n","        attns = self.softmax(attns.view(-1, len_key))\n","\n","        # return mean attention from all heads as coverage\n","        coverage = torch.mean(attns.view(b, self.num_heads, len_query, len_key), dim=1)\n","\n","        attns = self.attn_dropout(attns)\n","        attns = attns.view(b * self.num_heads, len_query, len_key)\n","\n","        # apply attns on value\n","        out = torch.bmm(attns, proj_value)  # batch_size*h x len_query x d_head\n","        out = out.view(b, self.num_heads, len_query, self.d_head).transpose(1, 2).contiguous()\n","\n","        out = self.fc_concat(out.view(b, len_query, self.num_heads * self.d_head))\n","\n","        out = self.dropout(out).add_(query)\n","        out = self.norm(out)\n","        return out, coverage\n","\n","class PositionwiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff, dropout):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.d_model = d_model\n","        self.d_ff = d_ff\n","        self.dropout = dropout\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_ff, d_model),\n","        )\n","        self.drop = nn.Dropout(self.dropout)\n","        self.norm = nn.LayerNorm(d_model)\n","\n","    def forward(self, inputs):\n","        out = self.fc(inputs)\n","        out = self.drop(out).add_(inputs)\n","        out = self.norm(out)\n","        return out\n","\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, num_heads, d_model, dropout, d_ff):\n","        super(EncoderLayer, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.d_ff = d_ff\n","        self.dropout = dropout\n","\n","        self.attention = MultiHeadAttention(self.num_heads, self.d_model, self.dropout)\n","\n","        self.ff = PositionwiseFeedForward(self.d_model, self.d_ff, self.dropout)\n","\n","    def forward(self, query, key, value, mask):\n","        out, _ = self.attention(query, key, value, mask)\n","        out = self.ff(out)\n","        return out\n","\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, num_heads, d_model, dropout, d_ff):\n","        super(DecoderLayer, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.d_ff = d_ff\n","        self.dropout = dropout\n","\n","        self.attention_tgt = MultiHeadAttention(self.num_heads, self.d_model, self.dropout)\n","\n","        self.attention_src = MultiHeadAttention(self.num_heads, self.d_model, self.dropout)\n","\n","        self.ff = PositionwiseFeedForward(d_model, self.d_ff, self.dropout)\n","\n","    def forward(self, query, key, value, context, mask_tgt, mask_src):\n","        out, _ = self.attention_tgt(query, key, value, mask_tgt)\n","        out, coverage = self.attention_src(out, context, context, mask_src)\n","        out = self.ff(out)\n","        return out, coverage\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, vocab_size, num_heads, d_model, dropout, d_ff, num_layers=6, padding_idx=1):\n","        super(Encoder, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.padding_idx = padding_idx\n","        self.num_layers = num_layers\n","        self.d_ff = d_ff\n","        self.dropout = dropout\n","\n","        self.embeddings = nn.Embedding(self.vocab_size, self.d_model, padding_idx=self.padding_idx)\n","\n","        self.pos_emb = PositionalEncoding(self.d_model, self.dropout, max_len=512)\n","\n","        self.layers = nn.ModuleList(\n","            [EncoderLayer(self.num_heads, self.d_model, self.dropout, self.d_ff) for _ in range(self.num_layers)]\n","        )\n","\n","    def forward(self, src):\n","        context = self.embeddings(src)  # batch_size x len_src x d_model\n","\n","        context = self.pos_emb(context)\n","\n","        mask_src = src.data.eq(self.padding_idx).unsqueeze(1)\n","        for _, layer in enumerate(self.layers):\n","            context = layer(context, context, context, mask_src)  # batch_size x len_src x d_model\n","        return context, mask_src\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, num_heads, d_model, dropout, d_ff, num_layers=6, padding_idx=1):\n","        super(Decoder, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.padding_idx = padding_idx\n","        self.num_layers = num_layers\n","        self.d_ff = d_ff\n","        self.dropout = dropout\n","\n","        self.embedding = nn.Embedding(self.vocab_size, self.d_model, padding_idx=self.padding_idx)\n","\n","        self.pos_emb = PositionalEncoding(self.d_model, self.dropout, max_len=512)\n","\n","        self.layers = nn.ModuleList(\n","            [DecoderLayer(self.num_heads, self.d_model, self.dropout, self.d_ff) for _ in range(self.num_layers)]\n","        )\n","\n","        self.fc = nn.Linear(self.d_model, self.vocab_size, bias=True)\n","\n","        # tie weight between word embedding and generator\n","        self.fc.weight = self.embedding.weight\n","\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","        # pre-save a mask to avoid future information in self-attentions in decoder\n","        # save as a buffer, otherwise will need to recreate it and move to GPU during every call\n","        mask = torch.ByteTensor(np.triu(np.ones((self.d_model, self.d_model)), k=1).astype('uint8'))\n","        self.register_buffer('mask', mask)\n","\n","    def forward(self, tgt, context, mask_src):\n","        out = self.embedding(tgt)  # batch_size x len_tgt x d_model\n","\n","        out = self.pos_emb(out)\n","\n","        len_tgt = tgt.size(1)\n","        mask_tgt = tgt.data.eq(self.padding_idx).unsqueeze(1) + self.mask[:len_tgt, :len_tgt]\n","        mask_tgt = torch.gt(mask_tgt, 0)\n","        for _, layer in enumerate(self.layers):\n","            out, coverage = layer(out, out, out, context, mask_tgt, mask_src)  # batch_size x len_tgt x d_model\n","\n","        out = self.fc(out)  # batch_size x len_tgt x bpe_size\n","\n","        out = self.logsoftmax(out.view(-1, self.vocab_size))\n","        return out, coverage\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(self, src_vocab, tgt_vocab, num_heads, d_model, dropout, d_ff, num_layers=6, padding_idx=1):\n","        super(Transformer, self).__init__()\n","        self.src_vocab = src_vocab\n","        self.src_vocab_size = len(src_vocab)\n","        self.tgt_vocab = tgt_vocab\n","        self.tgt_vocab_size = len(tgt_vocab)\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","        self.d_ff = d_ff\n","        self.num_layers = num_layers\n","        self.dropout = dropout\n","        self.padding_idx = padding_idx\n","\n","        self.encode = Encoder(self.src_vocab_size, self.num_heads, self.d_model, self.dropout, self.d_ff,\n","                              self.num_layers, self.padding_idx)\n","        self.decode = Decoder(self.tgt_vocab_size, self.num_heads, self.d_model, self.dropout, self.d_ff,\n","                              self.num_layers, self.padding_idx)\n","\n","    def forward(self, src, src_sizes, tgt, tgt_sizes, ):\n","        context, mask_src = self.encode(src)\n","        outputs, _ = self.decode(tgt, context, mask_src)\n","\n","        probas = outputs.view(src.size(0), -1, self.tgt_vocab_size)\n","        \n","        return probas, tgt_sizes-1\n","\n","    def decode_greedy(self, inputs, max_seq_length=50, fixed_length=False):\n","\n","        self.eval()\n","        with torch.no_grad():\n","            \n","            idx_sos, idx_eos = self.tgt_vocab('<sos>'), self.tgt_vocab('<eos>')\n","\n","            context, mask_src = self.encode(inputs)\n","\n","            batch_size = inputs.size(0)\n","            decode_input = torch.ones(batch_size, 1).fill_(idx_sos).type_as(inputs)\n","\n","            dec_output_sizes = torch.LongTensor(batch_size).fill_(max_seq_length).type_as(inputs)\n","\n","            dec_outputs = []\n","            for step in range(max_seq_length):\n","                outputs, _ = self.decode(decode_input, context, mask_src)\n","                outputs = outputs.view(batch_size, -1, self.tgt_vocab_size)\n","\n","                dec_outputs.append(outputs[:, step, :].unsqueeze(1))\n","\n","                preds = torch.max(outputs[:, -1, :], dim=1)[1]\n","\n","                dec_output_sizes[preds.eq(idx_eos) * dec_output_sizes.gt(step)] = step\n","                if not fixed_length and dec_output_sizes.le(step + 1).all():\n","                    dec_output_sizes += 1\n","                    break\n","\n","                decode_input = torch.cat([decode_input, preds.unsqueeze(1)], dim=1)\n","\n","            dec_outputs = torch.cat(dec_outputs, dim=1)\n","\n","        return dec_outputs, dec_output_sizes\n","\n","    def decode_beam(self, inputs, labels=None, max_seq_length=50, beam_size=64, alpha=0.1, beta=0.3):\n","\n","        context, mask_src = self.encode(inputs)\n","\n","        max_seq_len = labels.size(1) if labels is not None else max_seq_length\n","\n","        dec_outputs = []\n","        for idx in range(context.size(0)):\n","            target, _ = beam_search(self, self.tgt_vocab, context[idx].unsqueeze(0), mask_src[idx].unsqueeze(0),\n","                                    beam_size=beam_size, alpha=alpha, beta=beta, max_seq_len=max_seq_len)\n","            dec_outputs.append(target)\n","\n","        return dec_outputs\n","\n","\n","def beam_search(model, vocab, context, mask_src, beam_size=64, alpha=0.1, beta=0.3, max_seq_len=64):\n","    probas = []\n","    preds = []\n","    probs = []\n","    coverage_penalties = []\n","\n","    vocab_size = len(vocab)\n","    idx_sos, idx_eos, idx_pad = vocab('<sos>'), vocab('<eos>'), vocab('<pad>')\n","\n","    decode_inputs = torch.LongTensor([idx_sos]).unsqueeze(1)\n","    if next(model.parameters()).is_cuda:\n","        decode_inputs = decode_inputs.cuda()\n","\n","    decode_outputs, coverage = model.decode(decode_inputs, context, mask_src)\n","\n","    scores, scores_idx = decode_outputs.view(-1).topk(beam_size)\n","    beam_idx = scores_idx / vocab_size\n","    pred_idx = (scores_idx - beam_idx * vocab_size).view(beam_size, -1)\n","\n","    decode_inputs = torch.cat((decode_inputs.repeat(beam_size, 1), pred_idx), 1)\n","    context = context.repeat(beam_size, 1, 1)\n","\n","    remaining_beams = beam_size\n","    for step in range(max_seq_len):\n","        decode_outputs, coverage = model.decode(decode_inputs, context, mask_src)\n","\n","        decode_outputs = decode_outputs.view(remaining_beams, -1, vocab_size)\n","        decode_outputs = scores.unsqueeze(1) + decode_outputs[:, -1, :]\n","        scores, scores_idx = decode_outputs.view(-1).topk(remaining_beams)\n","\n","        beam_idx = scores_idx / vocab_size\n","        pred_idx = (scores_idx - beam_idx * vocab_size).view(remaining_beams, -1)\n","\n","        decode_inputs = torch.cat((decode_inputs[beam_idx], pred_idx), 1)\n","\n","        index = decode_inputs[:, -1].eq(idx_eos) + decode_inputs[:, -1].eq(idx_pad)\n","        finished = index.nonzero().flatten()\n","        continue_idx = (index ^ 1).nonzero().flatten()\n","\n","        for idx in finished:\n","            probas.append(scores[idx].item())\n","            preds.append(decode_inputs[idx, :].tolist())\n","            probs.append(coverage[idx, :, :])\n","\n","            atten_prob = torch.sum(coverage[idx, :, :], dim=0)\n","            coverage_penalty = torch.log(atten_prob.masked_select(atten_prob.le(1)))\n","            coverage_penalty = beta * torch.sum(coverage_penalty).item()\n","            coverage_penalties.append(coverage_penalty)\n","\n","            remaining_beams -= 1\n","\n","        if len(continue_idx) > 0:\n","            scores = scores.index_select(0, continue_idx)\n","            decode_inputs = decode_inputs.index_select(0, continue_idx)\n","            context = context.index_select(0, continue_idx)\n","\n","        if remaining_beams <= 0:\n","            break\n","\n","    len_penalties = [math.pow(len(pred), alpha) for pred in preds]\n","    #     final_scores = [probas[i] / len_penalties[i] + coverage_penalties[i] for i in range(len(preds))]\n","    final_scores = [probas[i] / len_penalties[i] for i in range(len(preds))]\n","\n","    sorted_scores_arg = sorted(range(len(preds)), key=lambda i: -final_scores[i])\n","\n","    best_beam = sorted_scores_arg[0]\n","\n","    return preds[best_beam], probs[best_beam]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lnmQImrY53Ae","colab_type":"code","colab":{}},"cell_type":"code","source":["model_cpu = Transformer(input_vocab, output_vocab, num_heads=8, d_model=512, \n","                        dropout=0.1, d_ff=1024, num_layers=6, padding_idx=IDX_PAD)\n","\n","outputs_cpu = model_cpu(inputs_cpu, input_sizes_cpu, labels_cpu, label_sizes_cpu)\n","\n","# print(outputs_cpu.shape, output_sizes_cpu.shape)\n","\n","# outputs_cpu, output_sizes_cpu = model_cpu.decode_greedy(inputs_cpu, labels_cpu)\n","\n","# print(outputs_cpu.shape, output_sizes_cpu.shape)\n","\n","# outputs_cpu, output_sizes_cpu = model_cpu.decode_beam(inputs_cpu, labels_cpu)\n","\n","# print(outputs_cpu.shape, output_sizes_cpu.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dmnKT97y53Ai","colab_type":"code","colab":{}},"cell_type":"code","source":["class STSDecoder(object):\n","    def __init__(self, vocab):\n","        self.vocab = vocab\n","\n","    @staticmethod\n","    def decode_labels(labels, label_sizes, vocab):\n","        idx_sos, idx_eos, idx_pad = vocab('<sos>'), vocab('<eos>'), vocab('<pad>')\n","        lseq = []\n","        for seq, size in zip(labels, label_sizes):\n","            lseq.append(\n","                ' '.join([vocab(c.item()) for c in seq[0:size - 1] if c.item() not in [idx_sos, idx_eos, idx_pad]])\n","            )\n","\n","        return lseq\n","\n","    @staticmethod\n","    def decode_probas(probas, probas_sizes, vocab, probabilities=False):\n","        max_vals, max_indices = torch.max(probas, 2)\n","        idx_sos, idx_eos, idx_pad = vocab('<sos>'), vocab('<eos>'), vocab('<pad>')\n","\n","        decoded_seq = []\n","        for seq_idx, seq_len, seq_proba in zip(max_indices.cpu(), probas_sizes, max_vals):\n","            txt, probas = '', []\n","\n","            for i in range(min(seq_len, len(seq_idx))):\n","                c = seq_idx[i].item()\n","                if c in [idx_sos, idx_eos, idx_pad]:\n","                    continue\n","                txt += vocab(c) + ' '\n","                probas.append(math.exp(seq_proba[i].item()))\n","\n","            if probabilities:\n","                decoded_seq.append((txt.strip(), stats.mean(probas) if len(probas) > 0 else 0))\n","            else:\n","                decoded_seq.append(txt.strip())\n","        return decoded_seq\n","\n","    def __call__(self, inputs, inputs_sizes, labels=None, label_sizes=None, probabilities=False):\n","\n","        decoder_seq = self.decode_probas(inputs, inputs_sizes, self.vocab, probabilities=probabilities)\n","\n","        label_seq = None\n","        if labels is not None and label_sizes is not None:\n","            label_seq = self.decode_labels(labels, label_sizes, self.vocab)\n","\n","        return decoder_seq, label_seq"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VkEP5OzP53Al","colab_type":"code","colab":{}},"cell_type":"code","source":["class LabelSmoothingLoss(nn.Module):\n","    def __init__(self, tgt_vocab_size, label_smoothing=0.0, padding_idx=0):\n","        super(LabelSmoothingLoss, self).__init__()\n","        assert 0.0 < label_smoothing <= 1.0\n","        self.ignore_index = padding_idx\n","\n","        smoothing_value = label_smoothing / (tgt_vocab_size - 2)\n","        one_hot = torch.full((tgt_vocab_size,), smoothing_value)\n","        one_hot[self.ignore_index] = 0\n","        self.register_buffer('one_hot', one_hot.unsqueeze(0))\n","\n","        self.confidence = 1.0 - label_smoothing\n","\n","    def forward(self, outputs, output_sizes, targets, target_sizes):\n","        b, t, c = outputs.size()\n","        outputs = outputs.view(b * t, c)\n","\n","        b, t = targets.size()\n","        targets = targets.view(b * t)        \n","        \n","        model_prob = self.one_hot.repeat(targets.size(0), 1)\n","        model_prob.scatter_(1, targets.unsqueeze(1), self.confidence)\n","        model_prob.masked_fill_((targets == self.ignore_index).unsqueeze(1), 0)\n","\n","        return F.kl_div(outputs, model_prob, reduction='sum')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3jmzf6rS53Ao","colab_type":"code","colab":{}},"cell_type":"code","source":["class NoamOptimizer(optim.Adam):\n","    def __init__(self, params, d_model, factor=2, warmup_steps=4000, betas=(0.9, 0.98), eps=1e-9):\n","        super(NoamOptimizer, self).__init__(params, betas=betas, eps=eps)\n","        self.d_model = d_model\n","        self.warmup_steps = warmup_steps\n","        self.lr = 0\n","        self.step_num = 0\n","        self.factor = factor\n","\n","    def step(self, closure=None):\n","        self.step_num += 1\n","        self.lr = self.lrate(self.step_num)\n","        for group in self.param_groups:\n","            group['lr'] = self.lr\n","        super(NoamOptimizer, self).step()\n","\n","    def lrate(self, epoch):\n","        return self.factor * self.d_model ** (-0.5) * min(epoch ** (-0.5), epoch * self.warmup_steps ** (-1.5))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DTvyvmd853Aq","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch import nn\n","\n","class AccuracyScorer(nn.Module):\n","\n","    def __init__(self, pad_index=0):\n","        super(AccuracyScorer, self).__init__()\n","\n","        self.pad_index = pad_index\n","\n","    def forward(self, outputs, output_sizes, targets, target_sizes):\n","\n","        batch_size, seq_len, vocabulary_size = outputs.size()\n","\n","        outputs = outputs.view(batch_size * seq_len, vocabulary_size)\n","        targets = targets.view(batch_size * seq_len)\n","\n","        predicts = outputs.argmax(dim=1)\n","        corrects = predicts == targets\n","\n","        corrects.masked_fill_((targets == self.pad_index), 0)\n","\n","        correct_count = corrects.sum().item()\n","        count = (targets != self.pad_index).sum().item()\n","\n","        return correct_count / float(count)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f9teEndV53As","colab_type":"code","colab":{}},"cell_type":"code","source":["# https://discuss.pytorch.org/t/implementation-of-function-like-numpy-roll/964/8\n","def roll(x, shift, dim=-1, fill_pad = None):\n","\n","    if 0 == shift:\n","        return x\n","\n","    elif shift < 0:\n","        shift = -shift\n","        gap = x.index_select(dim, torch.arange(shift).to(x.device))\n","        if fill_pad is not None:\n","            gap = fill_pad * torch.ones_like(gap, device=x.device)\n","        return torch.cat([x.index_select(dim, torch.arange(shift, x.size(dim)).to(x.device)), gap], dim=dim)\n","\n","    else:\n","        shift = x.size(dim) - shift\n","        gap = x.index_select(dim, torch.arange(shift, x.size(dim)).to(x.device))\n","        if fill_pad is not None:\n","            gap = fill_pad * torch.ones_like(gap, device=x.device)\n","        return torch.cat([gap, x.index_select(dim, torch.arange(shift).to(x.device))], dim=dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iflWWLXP53Av","colab_type":"code","colab":{}},"cell_type":"code","source":["m = Metric([('train_loss', np.inf), ('train_score', np.inf), ('valid_loss', np.inf), ('valid_score', 0),\n","            ('train_lr', 0), ('valid_cer', np.inf)])\n","\n","model = Transformer(input_vocab, output_vocab, num_heads=8, d_model=512,  dropout=0.1, d_ff=1024, \n","                    num_layers=6, padding_idx=IDX_PAD)\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        torch_weight_init(p)\n","\n","if H.USE_CUDA:\n","    model.cuda()\n","\n","logging.info(model_summary(model, line_length=100))\n","\n","# if H.PRELOAD_MODEL_PATH:\n","#     path = os.path.join(H.EXPERIMENT, H.PRELOAD_MODEL_PATH)\n","#     state = torch.load(path)\n","#     model.load_state_dict(state)\n","#     logging.info(\"Preloaded model: {}\".format(path))\n","\n","if H.PRELOAD_MODEL_PATH:\n","    path = os.path.join(H.EXPERIMENT, H.PRELOAD_MODEL_PATH)\n","    state = torch.load(path)\n","    model.load_state_dict(state)\n","    logging.info(\"Preloaded model: {}\".format(path))    \n","    \n","    \n","criterion = LabelSmoothingLoss(len(output_vocab), label_smoothing=H.LABEL_SMOOTHING, padding_idx=IDX_PAD)\n","if H.USE_CUDA:\n","    criterion.cuda()\n","    \n","sts_decoder = STSDecoder(output_vocab)\n","\n","#scorer = Scorer()\n","scorer = AccuracyScorer(pad_index=IDX_PAD)\n","\n","optimizer = optim.Adam(list(filter(lambda p: p.requires_grad, model.parameters())),\n","                       amsgrad=False,\n","                       betas=(0.9, 0.999),\n","                       eps=1e-08,\n","                       lr=H.LR,\n","                       weight_decay=H.WEIGHT_DECAY)\n","\n","# optimizer = NoamOptimizer(list(filter(lambda p:p.requires_grad, model.parameters())),\n","#                           d_model=256, factor=2, warmup_steps=20000, betas=(0.9, 0.98), eps=1e-9)\n","\n","stopping = Stopping(model, patience=H.STOPPING_PATIENCE)\n","\n","scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[H.LR_LAMBDA])\n","\n","tlogger = TensorboardLogger(root_dir=H.EXPERIMENT, experiment_dir=H.TIMESTAMP)  # PytorchLogger()\n","\n","checkpoint = Checkpoint(model, optimizer, stopping, m,\n","                        root_dir=H.EXPERIMENT, experiment_dir=H.TIMESTAMP, restore_from=-1,\n","                        interval=H.CHECKPOINT_INTERVAL, verbose=0)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q7rCH-wZ53Ay","colab_type":"code","colab":{}},"cell_type":"code","source":["# path = os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar')\n","# state = torch.load(path)\n","# model.load_state_dict(state)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pE8rrUW053A2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"outputId":"71bc9ed1-57aa-47af-ed9d-edc212be236e","executionInfo":{"status":"error","timestamp":1556003843594,"user_tz":-180,"elapsed":1046,"user":{"displayName":"Александр Поляков","photoUrl":"","userId":"09711156570659448898"}}},"cell_type":"code","source":["epoch_start = 1\n","if H.CHECKPOINT_RESTORE:\n","    epoch_start = checkpoint.restore() + 1\n","#     train_loader.batch_sampler.shuffle(epoch_start)\n","\n","epoch = epoch_start\n","try:\n","    epoch_itr = tlogger.set_itr(range(epoch_start, H.MAX_EPOCHS + 1))\n","\n","    for epoch in epoch_itr:\n","        \n","#         with DelayedKeyboardInterrupt():\n","\n","        model.train(True)\n","\n","#         scheduler.step()\n","    \n","        train_lr = [float(param_group['lr']) for param_group in optimizer.param_groups][0]\n","\n","        total_size, total_loss, total_score = 0, 0.0, 0.0\n","        for idx_batch, batch in enumerate(train_iter):\n","            inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n","            labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n","            if next(model.parameters()).is_cuda:\n","                inputs, labels = inputs.cuda(), labels.cuda()\n","\n","            probas, proba_sizes = model(inputs, input_sizes, labels, label_sizes) \n","\n","            loss = criterion(probas, proba_sizes, roll(labels, -1, dim=-1, fill_pad=IDX_PAD), label_sizes-1)\n","            total_loss += loss.item()      \n","            \n","            preds_seq, label_seq = sts_decoder(probas, proba_sizes, labels, label_sizes)\n","            total_score += scorer(preds_seq, label_seq)\n","#             total_score += scorer(probas, proba_sizes, labels, label_sizes)\n","            \n","            total_size += inputs.size(0)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            \n","            if H.MAX_GRAD_NORM is not None:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), H.MAX_GRAD_NORM)\n","            optimizer.step()\n","\n","            del probas\n","            del loss\n","            \n","        m.train_loss = total_loss / total_size\n","        m.train_score = 1.0 - min(1.0, total_score / total_size)\n","        m.train_lr = train_lr\n","    \n","        #-----------------------------------------------------------\n","        \n","        model.eval()\n","        \n","        with torch.no_grad():\n","\n","            hypotheses = []\n","            references = []\n","            total_size, total_loss, total_score = 0, 0.0, 0.0\n","            for idx_batch, batch in enumerate(valid_iter):\n","                inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n","                labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n","                if next(model.parameters()).is_cuda:\n","                    inputs, labels = inputs.cuda(), labels.cuda()\n","\n","                probas, proba_sizes = model.decode_greedy(inputs, labels.size(1), fixed_length=True)\n","                \n","                loss = criterion(probas, proba_sizes, roll(labels, -1, dim=-1, fill_pad=IDX_PAD), label_sizes-1)\n","                total_loss += loss.item()      \n","\n","                preds_seq, label_seq = sts_decoder(probas, proba_sizes, labels, label_sizes)\n","                total_score += scorer(preds_seq, label_seq)\n","#                 total_score += scorer(probas, proba_sizes, labels, label_sizes)\n","\n","                total_size += inputs.size(0)\n","                \n","            del probas\n","            del loss\n","\n","        m.valid_loss = total_loss / total_size\n","        m.valid_score = 1.0 - min(1.0, total_score / total_size)\n","\n","        if checkpoint:\n","            checkpoint.step(epoch)\n","\n","        stopping_flag = stopping.step(epoch, m.valid_loss, m.valid_score)\n","\n","        epoch_itr.log_values(m.train_loss, m.train_score, m.train_lr, m.valid_loss, m.valid_score,\n","                             stopping.best_score_epoch, stopping.best_score)\n","\n","        if stopping_flag:\n","            logger.info(\n","                \"Early stopping at epoch: %d, score %f\" % (stopping.best_score_epoch, stopping.best_score))\n","            break\n","\n","#             train_loader.batch_sampler.shuffle(epoch)\n","\n","except KeyboardInterrupt:\n","    logger.info(\"Training interrupted at: {}\".format(epoch))\n","    pass\n","\n","checkpoint.create(epoch)\n","\n","model.load_state_dict(stopping.best_score_state)\n","torch.save(model.state_dict(), os.path.join(H.EXPERIMENT, H.MODEL_NAME + '.tar'))\n","\n","logger.info(repr(tlogger))\n","logger.info(repr(stopping))\n","logger.info(repr(checkpoint))\n","\n","logger.info(\"Training end.\")"],"execution_count":57,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-8445c8c05787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mpreds_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msts_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#             total_score += scorer(probas, proba_sizes, labels, label_sizes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'targets' and 'target_sizes'"]}]},{"metadata":{"id":"MJPYVWgT53A4","colab_type":"code","colab":{}},"cell_type":"code","source":["model_pre = Transformer(input_vocab, output_vocab, num_heads=8, d_model=512,  dropout=0.1, d_ff=1024, \n","                    num_layers=6, padding_idx=IDX_PAD)\n","\n","\n","if H.USE_CUDA:\n","    model_pre.cuda()\n","\n","path = os.path.join(H.EXPERIMENT, 'Eng2Ger_TRANSFORMER' + '.tar')\n","state = torch.load(path)\n","model_pre.load_state_dict(state)\n","\n","scorer = Scorer()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"33vBLwvZ53A7","colab_type":"code","colab":{}},"cell_type":"code","source":["hypotheses = []\n","references = []\n","for idx_batch, batch in enumerate(test_iter):\n","    inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n","    labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n","    if next(model_pre.parameters()).is_cuda:\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","\n","    probas, proba_sizes = model_pre.decode_greedy(inputs, labels.size(1))\n","    break\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nN-KxTl653A9","colab_type":"code","colab":{},"outputId":"7fc71883-09d3-4275-bf75-f1511a36e4ec"},"cell_type":"code","source":["%%time \n","\n","model_pre.eval()\n","with torch.no_grad():\n","\n","    hypotheses = []\n","    references = []\n","    for idx_batch, batch in enumerate(test_iter):\n","        inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n","        labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n","        if next(model_pre.parameters()).is_cuda:\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        probas, proba_sizes = model_pre.decode_greedy( inputs, H.SEQ_MAX_LEN)\n","        \n","        preds_seq, label_seq = sts_decoder(probas, proba_sizes, labels, label_sizes)\n","\n","        hypotheses.extend(preds_seq)\n","        references.extend(label_seq)\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 1min 13s, sys: 87.8 ms, total: 1min 13s\n","Wall time: 1min 13s\n"],"name":"stdout"}]},{"metadata":{"id":"BM8nxDS953BA","colab_type":"code","colab":{},"outputId":"03b588a7-eaf4-4650-dcd1-634bece77289"},"cell_type":"code","source":["from lib.scorer import Scorer\n","\n","bleu = Scorer.get_moses_multi_bleu(hypotheses, references, lowercase=False)\n","wer, cer = Scorer.get_wer_cer(hypotheses, references)\n","acc = Scorer.get_acc(hypotheses, references)\n","\n","\n","print('Test Summary \\n'\n","            'Bleu: {bleu:.3f}\\n'\n","            'WER:  {wer:.3f}\\n'\n","            'CER:  {cer:.3f}\\n'\n","            'ACC:  {acc:.3f}'.format(bleu=bleu, wer=wer * 100, cer=cer * 100, acc=acc * 100))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Summary \n","Bleu: 38.390\n","WER:  39.463\n","CER:  37.274\n","ACC:  18.671\n"],"name":"stdout"}]},{"metadata":{"id":"KelF6sl953BD","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","\n","model_pre.eval()\n","with torch.no_grad():\n","\n","    hypotheses = []\n","    references = []\n","    for idx_batch, batch in enumerate(test_iter):\n","        inputs, input_sizes = getattr(batch, SRC_FIELD_NAME)\n","        labels, label_sizes = getattr(batch, TGT_FIELD_NAME)\n","        if next(model.parameters()).is_cuda:\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        context, mask_src = model_pre.encode(inputs)\n","        \n","        max_seq_len = labels.size(1) if labels is not None else H.MAX_SEQ_LENGTH\n","\n","        outputs = model_pre.decode_beam(inputs, None, max_seq_len, beam_size=20, alpha=0.1, beta=0.3)\n","\n","        for entry in outputs:\n","            hypotheses.append(' '.join([output_vocab(t) for t in entry if t not in [IDX_PAD, IDX_SOS, IDX_EOS]]))\n","\n","        references.extend(STSDecoder.decode_labels(labels[:,1:], label_sizes-1, output_vocab)) \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7a95NU7J53BF","colab_type":"code","colab":{},"outputId":"aca9aa06-ae83-42fa-fead-e0a7b2e658ad"},"cell_type":"code","source":["from lib.scorer import Scorer\n","\n","bleu = Scorer.get_moses_multi_bleu(hypotheses, references, lowercase=False)\n","wer, cer = Scorer.get_wer_cer(hypotheses, references)\n","acc = Scorer.get_acc(hypotheses, references)\n","\n","\n","print('Test Summary \\n'\n","            'Bleu: {bleu:.3f}\\n'\n","            'WER:  {wer:.3f}\\n'\n","            'CER:  {cer:.3f}\\n'\n","            'ACC:  {acc:.3f}'.format(bleu=bleu, wer=wer * 100, cer=cer * 100, acc=acc * 100))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Summary \n","Bleu: 40.270\n","WER:  35.531\n","CER:  34.209\n","ACC:  22.051\n"],"name":"stdout"}]},{"metadata":{"id":"YHitiKW453BK","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"e5iOFTn-53BM","colab_type":"code","colab":{},"outputId":"82aa5dbd-155c-4ae9-a3cb-b2268f962436"},"cell_type":"code","source":["while True:\n","    seq_str = input(\"Type in a source sequence:\")\n","    print(\">> \", seq_str)\n","    if not len(seq_str):\n","        break\n","    #seq = seq_str.strip().lower().split()\n","    seq = tokenize_en(seq_str.strip().lower())\n","    print(seq)\n","\n","    seq_id = [input_vocab(tok) for tok in seq]\n","\n","    model_pre.eval()\n","    with torch.no_grad():\n","\n","        src_id_seq = torch.LongTensor(seq_id).view(1, -1)\n","        src_id_seq = src_id_seq.cuda() if torch.cuda.is_available() else src_id_seq\n","        \n","        probas, proba_sizes = model_pre.decode_greedy( src_id_seq)\n","\n","        tgt_seq = STSDecoder.decode_probas(probas, proba_sizes, output_vocab)\n","        \n","        print(\"<< \", ' '.join(tgt_seq))\n","\n","print(\"Finished.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Type in a source sequence:I am at home.\n",">>  I am at home.\n","['i', 'am', 'at', 'home', '.']\n","<<  ich bin zu hause .\n","Type in a source sequence:\n",">>  \n","Finished.\n"],"name":"stdout"}]},{"metadata":{"id":"IbgtNQy253BP","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}